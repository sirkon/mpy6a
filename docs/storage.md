# Хранение данных

Работа RAFT строится как работа над [логом операций](log_operations.md). Репликация производится как развоз очередного 
элемента лога на машины-последователи, лог используется для восстановления состояния после запуска сервиса и т.д.

Из практики работы с одной библиотекой реализующей WAL известно, что задача восстановления данных из лога может 
быть весьма дорогой с точки зрения требуемого объёма оперативной памяти, особенно в случае большого числа долго живущих
сессий. Т.е. лог очень желательно сокращать в процессе функционирования при этом предоставляя достаточно дешёвый способ
восстановления состояния.

В материале ниже описывается предлагаемый подход реализующий эти пожелания.

## Описание восстановления данных.

Допустим, у нас есть слепок состояния A на момент времени t и лог операций, хранящий описания изменений произошедших
после t.

Чтобы восстановить состояния на момент падения нужно:

1. Построить внутреннее состояние соответствующее слепку.
2. Пробежать последовательно по операциям лога применяя каждую из них к состоянию.

Таким образом, состояние придёт к тому, что было когда была применена последняя операция из лога.

С логом всё примерно понятно, нужно понять какого рода данные у нас есть и каким образом из них нужно делать слепки.

## Описание системы хранения.

С данными на каждый конкретный момент времени t всё просто, "глобальное" состояние хранит:

* Сохранённые сессии, для которых нужно будет сделать повтор.
* Активные сессии.

Покажем, что сохранять слепок нужно для полного набора данных. Для это покажем трудно разрешимую ситуацию,
когда были сохранены только некоторые из данных. Обратим внимание, что операции изменения из лога могут располагаться
в хаотичном порядке, когда в логе лежат операции изменения совершенно разных сессий. Отсюда следует, что если мы 
сохранили состояние сессии A, но не сохранили состояние сессии B, а затем сдвинули лог исключая все записи относящиеся 
к сессии A, то мы можем не восстановить B корректно, т.к. операции мутирующие A могут перемежаться в логе с операциями 
для B.

Таким образом, текущее состояние при создании слепка необходимо сбрасывать **полностью**, т.к. в этом случае можно
почистить лог полностью решив задачу сформулированную в шапке. А иначе, при частичном сохранении, начало лога останется
на прежнем месте и лучшая оптимизация, что мы можем получить, это пропуск операций относящихся к сброшенным сессиям, 
что на фоне общего объёма работы может быть весьма малой величиной.

Далее рассмотрим

### Хранение сохранённых сессий

Про сохранённые сессии известно, что они затем будут возвращены, когда придёт их время, на повтор. В соответствии с
гарантиями, порядок повторов сессий детерминирован и соответствует порядку их времён начала повтора. Оптимально, таким
образом, упорядочивать записи таких сессий соответственно временам повтора. За счёт этого сам повтор станет очень 
простым:

1. Вычитали первую запись
2. Дождались времени повтора
3. Выполнили повтор
4. Повторяем начиная с шага 1

Естественно, реальный алгоритм чуть хитрее, но в любом случае сложность повтора будет равна сложности выполнения IO 
операций — которые будут производиться в любом случае, т.к. сами данные берутся оттуда.

Естественно, это будет не один файл, рассмотрим такую последовательность действий:

1. Сессия P сохраняется с временем повтора P(t)
2. На каком-то шаге делается слепок содержащий сессию P.
3. Затем, по прошествии какого-то времени, сессия Q сохраняется с временем Q(t), причём Q(t) < P(t).

В этом случае мы можем применить подход т.н. LSM-деревьев, когда вместо одного файла с упорядоченными сессиями в них
мы можем иметь несколько, а правильный глобальный порядок обеспечивается алогоритмом сортировки слиянием.

Таким образом, когда данные сохранённых сессий превысили некоторый лимит, мы сбрасываем их на диск в новый файл,
в правильном порядке. А затем этот файл вычитывается одновременно с теми, что были созданы до этого и ещё не прочитаны
до конца.

### Хранение активных сессий

Здесь всё довольно просто, т.к. активные сессии нужны только для восстановления в память и достаточно просто закинуть
сессии в файл в произвольном порядке.

### Смежное хранение сессий в слепках.

Как уже было замечено выше, слепки необходимо делать для всего текущего состояния. Если хранить сохранённые и активные
сессии раздельно, то мы получим две операции создания файла, которые совсем не лёгкие и неплохо было бы их подсократить.

Можно объеденить эти данные в файлах слепков, например следующим образом:

| Длина данных сохранённых сессий | Данные сохранённых сессий | Длина данных активных сессий | Дамп активных сессий |
|---------------------------------|---------------------------|------------------------------|----------------------|

В результате, данные слепки будут играть роль одновременно и точек восстановления состояния, и источником сессий на 
повтор — для этой операции будет вычитываться только часть файла которая хранит "данные сохранённых сессий".

### Операция объединения и слепки.

Чтобы уменьшить количество файлов с повторяемыми сессиями, могут составляться новые, полученные "сортировкой слиянием",
а после получения объединённого файла старые, из которых получен новый, должны исключаться для дальнейшего 
использования.

Совершенно точно нельзя удалять активный (последний) слепок, поэтому операция слияния не должна его затрагивать. Старые
слепки, соответственно, могут использоваться без ограничений — они больше не нужны.

### Управление файлами

Система должна знать, в каких файлах лежат данные сохранённых сессий, в какой файл пишется лог и какова его текущая 
длина.

Эта информация постоянно хранится в оперативной памяти и должна сохраняться в слепках ровно по той же причине, почему
необходимо сбрасывать оба типа сессий одновременно – хотя бы потому, что часть операций модифицирует состояние 
связанное с файлами, например команда "извлечь сессию длинной N байт из файла с сохранёнными сессиями". 

Фиксируем:

| Длина данных сохранённых сессий  | Данные сохранённых сессий | Длина данных активных сессий | Дамп активных сессий  | Длина дампа контроля файлов | Данные контроля файлов |
|---|-----|-----|----|-----------------------------|------------------------|

Большая часть операций с логом производится неявно, но есть и явное управление: переключение на другой файл лога.

### Замечание по поводу источников сохранённых сессий.

Их у нас три:

* Слепки
* Сохранённые сессии ещё не слитые в слепок, т.е. находящиеся в оперативной памяти.
* Слитые источники сохранённых сессий.

Т.е. команда "восстановить сессию из источника" должна содержать так же информацию из какого рода источника это нужно
сделать, т.к. правила итерации и переход на следующий элемент для них различны:

* В слепках и слитых источниках анализируется содержимое файлов и данные сессии вычленяются по результатам 
  анализа, а в результате подтверждения вычитки происходит сдвиг в файле на длину куска описывающего сессию.
* В сохранённых сессиях из оперативной памяти говорится "взять сохранённую сессию из памяти", подразумевая что
  будет выбрана первая сессия оттуда, а подтверждение вычитки приводит к удалению этой первой сессии из контейнера.

### Выбор слепка при старте сервиса.

При старте узла сервис должен понять, в каком файле лежит последний слепок. Есть два варианта:

1. MMap-ить название последнего слепка.
2. Вести лог с названиями слепок.

Первый вариант сложнее в реализации чем второй и протирает дырку в SSD — хотя для прода использовать SSD будет
неправильно НМВ, но при разработке наверняка будет он, поэтому заботимся о разработчиках и используем лог.

Названия файлов будут храниться в текстовом логе, построчно — такой способ здесь получается наиболее экономичным так 
как оверхед получается всего 1 байт на одну строку, с бинарным представлением будет не меньше.

При старте будет вычитываться последняя непустая строка.

При подходе с логами, как обычно, возникает проблема их избыточного протухания решаемая с помощью ротации. 

Но переключаться единовременно с записью не очень хорошо, т.к. это приводит к трём системным вызовам:

1. Создание нового временного файла
2. Запись в этот файл данных
3. Переименование созданного файла в нужное имя.

Хотелось бы избежать такого большого числа сисколов в рамках выполнения одной операции, поэтому лучше применить
следующий подход:

1. Пишем имя нового слепка в лог.

После этого в фоне запускается операция:

1. Если лог пока ещё достаточно мал, то выходим.
2. Иначе создаём новый временный файл.
3. Пишем имя текущего слепка в него.
4. Переименовываем временный файл в имя лога.

## Процедура создания слепка

Она не выполняется мгновенно по очевидным причинам и за время создания может происходить масса событий 
полагающихся на систему, поэтому нужен подход который бы минимизировал время её недоступности на момент выполнения
этой операции. Т.е. некая асинхронность исполнения, когда мы вначале подготавливаем слепок в фоне, а затем просто
регистрируем его.

Будет работать, например, следующий подход:

* В структуру ответа на AppendEntries RAFT-а включается поле "слепок на состояние t подготовлен" — он заполняется когда
  слепок на узле создан.


1. С помощью лога декларируется операция "подготовка слепка состояния для данного индекса состояния".
2. Делается полный клон состояния — клонируются контейнер сохранённых сессий, список активных сессий. После чего
   начинается создание слепка (в фоне).
3. Создаётся новое текущее состояние с пустым контейнером сохранённых сессий но со списком активных сессий являющихся 
   копией текущего.
4. Старое текущее состояние не удаляется, а становится дублирующим. С этого момента все операции применяются как к
   текущему состоянию, так и к дублирующему.

После выполнения пункта 1 лидер запускает отслеживание ответов на AppendEntries, подсчитывая количество узлов 
выполнивших подготовку слепка.

После завершения подготовки слепка на лидере некий фоновый процесс на нём переходит в состояние ожидания завершения
этой операции на кворумном числе последователей, причём эта операция (ожидание) занимает конечное время:

* Если за конечное время не получилось создать кворумное число слепков, то по логу рассылается операция 
  "сбросить слепок". Её применение к состоянию означает:
  * Удаление слепка.
  * Удаление текущего состояния, удаление клонированного состояния, текущим состоянием становится дублированное.
* Если получено подтверждение создания, по логу рассылается операция "применить слепок", которая:
  * Регистрирует слепок.
  * Удаляет клонированное состояние, удаляет дублирующее состояние.

## Обработка состояния для кандидата ставшего лидером.

Ситуация, когда кандидат становится лидером, означает, что процессы на старом лидере, проводимые вне лога, более не 
выполняются. В частности, это означает, что активные сессии завершены неуспехом, так же как и создание слепка.

Поэтому лидер применяет следующие операции к состояния:

* Если в логе была операция подготовки слепка без соотв. записи "сбросить слепок" или "зарегистрировать слепок", то 
  нужно разослать операцию "сбросить слепок".
* Нужно сохранить сессии находящиеся в активном состоянии с какой-нибудь политикой времени повтора.

## Наглядная схема файлов хранения данных

![схема](storage.png)

